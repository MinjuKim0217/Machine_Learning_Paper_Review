{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Abstractive Text Summarization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gblDkJqWrXXQ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import re\n",
        "import pickle"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fG0kZ9BxlMx"
      },
      "source": [
        "# **Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9BryEGgtzd2"
      },
      "source": [
        "news=pd.read_excel(\"new.xlsx\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ5WKmxBuO8m"
      },
      "source": [
        "news.drop(['Source ', 'Time ', 'Publish Date'], axis=1, inplace=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Hc0btgpavkkj",
        "outputId": "c9e9d084-8b3c-4a05-8bca-202cbefb65dd"
      },
      "source": [
        "news.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Short</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4 ex-bank officials booked for cheating bank o...</td>\n",
              "      <td>The CBI on Saturday booked four former officia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Supreme Court to go paperless in 6 months: CJI</td>\n",
              "      <td>Chief Justice JS Khehar has said the Supreme C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>At least 3 killed, 30 injured in blast in Sylh...</td>\n",
              "      <td>At least three people were killed, including a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Why has Reliance been barred from trading in f...</td>\n",
              "      <td>Mukesh Ambani-led Reliance Industries (RIL) wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Was stopped from entering my own studio at Tim...</td>\n",
              "      <td>TV news anchor Arnab Goswami has said he was t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline                                              Short\n",
              "0  4 ex-bank officials booked for cheating bank o...  The CBI on Saturday booked four former officia...\n",
              "1     Supreme Court to go paperless in 6 months: CJI  Chief Justice JS Khehar has said the Supreme C...\n",
              "2  At least 3 killed, 30 injured in blast in Sylh...  At least three people were killed, including a...\n",
              "3  Why has Reliance been barred from trading in f...  Mukesh Ambani-led Reliance Industries (RIL) wa...\n",
              "4  Was stopped from entering my own studio at Tim...  TV news anchor Arnab Goswami has said he was t..."
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qissEWgevs1P",
        "outputId": "c8843706-e4f8-4b77-dbc2-dc403a5d89e2"
      },
      "source": [
        "news.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55104, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO_fE_NDvuv0"
      },
      "source": [
        "document=news['Short']\n",
        "summary=news['Headline']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY-3wqLnv16p",
        "outputId": "21c853f3-7fb3-46b4-9c04-a3cf1c7dac32"
      },
      "source": [
        "document[30], summary[30]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('According to the Guinness World Records, the most generations alive in a single family have been seven.  The difference between the oldest and the youngest person in the family was about 109 years, when Augusta Bunge&#39;s great-great-great-great grandson was born on January 21, 1989. The family belonged to the United States of America.',\n",
              " 'The most generations alive in a single family have been 7')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDQz2ZvdxZWw"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d04LDX5l2vFc"
      },
      "source": [
        "recognize the start and end of target sequence, pad them with start \"go\" and end \"stop\" tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4cg4tJwxW71",
        "outputId": "785c54f7-48a3-4fed-dec0-a3dda62c6ef8"
      },
      "source": [
        "summary=summary.apply(lambda x: '<go>'+x+'<stop>')\n",
        "summary.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    <go>4 ex-bank officials booked for cheating ba...\n",
              "1    <go>Supreme Court to go paperless in 6 months:...\n",
              "2    <go>At least 3 killed, 30 injured in blast in ...\n",
              "3    <go>Why has Reliance been barred from trading ...\n",
              "4    <go>Was stopped from entering my own studio at...\n",
              "Name: Headline, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWzmghYQyhJf"
      },
      "source": [
        "#### Tokenizing the texts into integer tokens\n",
        "\n",
        "특수기호 제거, 텍스트를 소문자로 변환, vocabulary dict을 단어의 빈번도로 재정렬. \n",
        "모델에 바로 input할  수 있도록 토크나이징\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5VT_81ZxW_P"
      },
      "source": [
        "filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "oov_token='<unk>'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-qpBdvkxXCX"
      },
      "source": [
        "document_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\n",
        "summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIWuDseWxXEv"
      },
      "source": [
        "document_tokenizer.fit_on_texts(document)\n",
        "summary_tokenizer.fit_on_texts(summary)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGFlAxPgxXHl"
      },
      "source": [
        "inputs = document_tokenizer.texts_to_sequences(document)\n",
        "targets = summary_tokenizer.texts_to_sequences(summary)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qh-tvfE1xXJo",
        "outputId": "b6653d0d-ecf0-4a71-afa2-6395e65b6306"
      },
      "source": [
        "summary_tokenizer.texts_to_sequences([\"This is a test\"])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[172, 21, 10, 76]]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SMlfaJpxXL6",
        "outputId": "7b173806-265b-4984-d5e3-a1da0e3c530e"
      },
      "source": [
        "summary_tokenizer.sequences_to_texts([[184, 22, 12, 71]])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['becomes be with pak']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awwMJXfhxXOS",
        "outputId": "0afc409b-38a3-4363-f3de-a67590aa3f38"
      },
      "source": [
        "encoder_vocab_size = len(document_tokenizer.word_index) + 1\n",
        "decoder_vocab_size = len(summary_tokenizer.word_index) + 1\n",
        "\n",
        "# vocab_size\n",
        "encoder_vocab_size, decoder_vocab_size"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76362, 44069)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxFiYUgc1SMN"
      },
      "source": [
        "#### Obtaining insights on lengths for defining maxlen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXOvnsi71RuP"
      },
      "source": [
        "document_lengths = pd.Series([len(x) for x in document])\n",
        "summary_lengths = pd.Series([len(x) for x in summary])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-xno0d9xXQs",
        "outputId": "f0eb0de1-0c44-49d6-e323-11939f563c73"
      },
      "source": [
        "document_lengths.describe()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    55104.000000\n",
              "mean       368.003049\n",
              "std         26.235510\n",
              "min        280.000000\n",
              "25%        350.000000\n",
              "50%        369.000000\n",
              "75%        387.000000\n",
              "max        469.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl9c8Kk9xXTP",
        "outputId": "3b9a612e-28f6-4b14-e514-ca6dc0987625"
      },
      "source": [
        "summary_lengths.describe()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    55104.000000\n",
              "mean        61.620282\n",
              "std          7.267463\n",
              "min         18.000000\n",
              "25%         57.000000\n",
              "50%         61.000000\n",
              "75%         67.000000\n",
              "max         94.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vwnTB-uxXVj"
      },
      "source": [
        "encoder_maxlen=400\n",
        "decoder_maxlen=75"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA-XS4Vx7XyM"
      },
      "source": [
        "#### Padding/Truncating sequences for identical sequence lengths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K23HNQct7ZL5"
      },
      "source": [
        "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlSrvR9p8PlD"
      },
      "source": [
        "## Creating dataset pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dP7ckd2nxXXv"
      },
      "source": [
        "inputs = tf.cast(inputs, dtype=tf.int32)\n",
        "targets = tf.cast(targets, dtype=tf.int32)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsKGw7zIxXaX"
      },
      "source": [
        "BUFFER_SIZE=20000\n",
        "BATCH_SIZE=64"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGciyBv8xXdH"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASpjCOBb9AxU"
      },
      "source": [
        "## Positional Encoding for adding notion of position among words as unlike RNN this is non-directional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6H86gtFxXfe"
      },
      "source": [
        "def get_angles(position, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return position * angle_rates"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hmJXDYPxXhn"
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "  angle_rads=get_angles(\n",
        "      np.arange(position)[:,np.newaxis],\n",
        "      np.arange(d_model)[np.newaxis,:],\n",
        "      d_model\n",
        "      )\n",
        "  angle_rads[:,0::2]=np.sin(angle_rads[:,0::2]) #array의 짝수 인덱스에 적용\n",
        "  angle_rads[:,1::2]=np.cos(angle_rads[:,1::2]) #array의 홀수 인덱스에 적용\n",
        "\n",
        "  pos_encoding=angle_rads[np.newaxis,...]\n",
        "\n",
        "  return tf.cast(pos_encoding, dtype=tf.float32)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQi81XJX-c8L"
      },
      "source": [
        "## Masking\n",
        "- padding mask for masking \"pad\" sequences\n",
        "- Lookahead mask for masking future words from contributing in prediction of current words in self attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHnXU2y1xXkN"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9HjIKftxXmY"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmK_-iqfQcTW"
      },
      "source": [
        "# Building the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uZJ7oHvQjqi"
      },
      "source": [
        "#### Scaled Dot Product"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb_GDuJrxXo6"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)\n",
        "    return output, attention_weights"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu5I-kyBROgh"
      },
      "source": [
        "#### Multi-Headed Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBSXTMdIQcjw"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, d_model, num_heads):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.num_heads=num_heads\n",
        "    self.d_model=d_model\n",
        "\n",
        "    assert d_model%self.num_heads==0\n",
        "\n",
        "    self.depth=d_model//self.num_heads\n",
        "    self.wq=tf.keras.layers.Dense(d_model)\n",
        "    self.wk=tf.keras.layers.Dense(d_model)\n",
        "    self.wv=tf.keras.layers.Dense(d_model)\n",
        "    self.dense=tf.keras.layers.Dense(d_model)\n",
        "\n",
        "  def split_heads(self,x,batch_size):\n",
        "    x=tf.reshape(x,(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(x, perm=[0,2,1,3])\n",
        "\n",
        "  def call(self, v, k, q, mask):\n",
        "    batch_size=tf.shape(q)[0]\n",
        "\n",
        "    q=self.wq(q)\n",
        "    k=self.wk(k)\n",
        "    v=self.wv(v)\n",
        "\n",
        "    q=self.split_heads(q, batch_size)\n",
        "    k=self.split_heads(k, batch_size)\n",
        "    v=self.split_heads(v, batch_size)\n",
        "\n",
        "    scaled_attention, attention_weights=scaled_dot_product_attention(\n",
        "        q,k,v,mask\n",
        "    )\n",
        "\n",
        "    scaled_attention=tf.transpose(scaled_attention, perm=[0,2,1,3])\n",
        "\n",
        "    concat_attention=tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "    output=self.dense(concat_attention)\n",
        "\n",
        "    return output, attention_weights\n",
        "  \n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smt34Ag-S59x"
      },
      "source": [
        "# Feed Forward Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ01qa9TQcmx"
      },
      "source": [
        "\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9Ms8m7YTTor"
      },
      "source": [
        "#### Fundamental Unit of Transformer Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKThXuycQcpa"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, training, mask):\n",
        "        attn_output, _ = self.mha(x, x, x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "        return out2\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RozSCsIEUcJ8"
      },
      "source": [
        "#### Fundamental Unit of Transformer decoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALBqIgBLT02u"
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)\n",
        "\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJnBPfoKUps3"
      },
      "source": [
        "#### Encoder consisting of multuple EncoderLayers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwDM2iWmQcry"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "    \n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "        return x"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl25iesuf3YZ"
      },
      "source": [
        "#### Decoder consisting of multiple DecoderLayers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQy1D7PjQcuD"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "        return x, attention_weights"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJPvC1zEgDAX"
      },
      "source": [
        "#### Transformer\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-AA4OxkQcwd"
      },
      "source": [
        "\n",
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "\n",
        "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output, attention_weights"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DNSfCS0hQC7"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1ErjSmdQcy5"
      },
      "source": [
        "\n",
        "# hyper-params\n",
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "EPOCHS = 20"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g7NyfKIhYgf"
      },
      "source": [
        "#### Adam optimizer with custom learning rate scheduling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jck62YuQc1e"
      },
      "source": [
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "    \n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-r35TQYiPej"
      },
      "source": [
        "#### Defining losses and other metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz9A4fetQc4i"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAqhSKL7iUS8"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XC1vlX4iUU8"
      },
      "source": [
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2W5Hp1O4iUXZ"
      },
      "source": [
        "train_loss=tf.keras.metrics.Mean(name='train_loss')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XJsjLppjYPD"
      },
      "source": [
        "#### Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjbp0uA9iUau"
      },
      "source": [
        "transformer = Transformer(\n",
        "    num_layers, \n",
        "    d_model, \n",
        "    num_heads, \n",
        "    dff,\n",
        "    encoder_vocab_size, \n",
        "    decoder_vocab_size, \n",
        "    pe_input=encoder_vocab_size, \n",
        "    pe_target=decoder_vocab_size,\n",
        ")"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7qlzW5TmNdl"
      },
      "source": [
        "#### masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbSC2tGJiUb7"
      },
      "source": [
        "\n",
        "def create_masks(inp, tar):\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ED58lRLmuJF"
      },
      "source": [
        "#### checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28I2u8wNiUd4"
      },
      "source": [
        "checkpoint_path = \"checkpoints\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print ('Latest checkpoint restored!!')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqa02bXdmzlO"
      },
      "source": [
        "#### Training Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXuUZAZymzIU"
      },
      "source": [
        "\n",
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(\n",
        "            inp, tar_inp, \n",
        "            True, \n",
        "            enc_padding_mask, \n",
        "            combined_mask, \n",
        "            dec_padding_mask\n",
        "        )\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HygaTwsbiUf_",
        "outputId": "7d313303-736c-4892-8a3c-3b7319468381"
      },
      "source": [
        "for epoch in range(5):\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_states()\n",
        "  \n",
        "    for (batch, (inp, tar)) in enumerate(dataset):\n",
        "        train_step(inp, tar)\n",
        "    \n",
        "        # 55k samples\n",
        "        # we display 3 batch results -- 0th, middle and last one (approx)\n",
        "        # 55k / 64 ~ 858; 858 / 2 = 429\n",
        "        if batch % 429 == 0:\n",
        "            print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, train_loss.result()))\n",
        "      \n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
        "    \n",
        "    print ('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss.result()))\n",
        "\n",
        "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 10.7056\n",
            "Epoch 1 Batch 429 Loss 9.6796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRm0wEU1u1h6"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HDu3tp-u6Rk"
      },
      "source": [
        "\n",
        "Predicting one word at a time at the decoder and appending it to the output; then taking the complete sequence as an input to the decoder and repeating until maxlen or stop keyword appears"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq1pvTGrQc6b"
      },
      "source": [
        "def evaluate(input_document):\n",
        "    input_document = document_tokenizer.texts_to_sequences([input_document])\n",
        "    input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "\n",
        "    encoder_input = tf.expand_dims(input_document[0], 0)\n",
        "\n",
        "    decoder_input = [summary_tokenizer.word_index[\"<go>\"]]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "    \n",
        "    for i in range(decoder_maxlen):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
        "\n",
        "        predictions, attention_weights = transformer(\n",
        "            encoder_input, \n",
        "            output,\n",
        "            False,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask\n",
        "        )\n",
        "\n",
        "        predictions = predictions[: ,-1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        if predicted_id == summary_tokenizer.word_index[\"<stop>\"]:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "troC3l-zQc9I"
      },
      "source": [
        "def summarize(input_document):\n",
        "    # not considering attention weights for now, can be used to plot attention heatmaps in the future\n",
        "    summarized = evaluate(input_document=input_document)[0].numpy()\n",
        "    summarized = np.expand_dims(summarized[1:], 0)  # not printing <go> token\n",
        "    return summary_tokenizer.sequences_to_texts(summarized)[0]  # since there is just one translated document"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n6unobsQc_4"
      },
      "source": [
        "summarize(\n",
        "    \"US-based private equity firm General Atlantic is in talks to invest about \\\n",
        "    $850 million to $950 million in Reliance Industries' digital unit Jio \\\n",
        "    Platforms, the Bloomberg reported. Saudi Arabia's $320 billion sovereign \\\n",
        "    wealth fund is reportedly also exploring a potential investment in the \\\n",
        "    Mukesh Ambani-led company. The 'Public Investment Fund' is looking to \\\n",
        "    acquire a minority stake in Jio Platforms.\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}